{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AMR in genomes from NCBI and from mysterious city\n",
        "First lets upload the mysterious city AMR presence-absence table\n",
        "We have 143 genomes (rows) with 505 AMR markers detected"
      ],
      "metadata": {
        "id": "Ha12BOWogfew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mysterious city  "
      ],
      "metadata": {
        "id": "KLXgWj1glKCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "## 505 combined CARD-manual Ids from mysterious samples\n",
        "url = 'https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/amr_mistery_table20230622_aroIds.tsv'\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_CM_mysterious = pd.read_csv(url, delimiter='\\t')\n",
        "# Rename the first column\n",
        "print(df_CM_mysterious.columns )\n",
        "df_CM_mysterious.columns.values[0] = 'ID'\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_CM_mysterious.head())\n",
        "\n",
        "# Get the dimensions of the DataFrame\n",
        "rows_df_CM_mysterious, columns_df_CM_mysterious = df_CM_mysterious.shape\n",
        "\n",
        "# Print the dimensions\n",
        "print(\"Number of rows:\", rows_df_CM_mysterious)\n",
        "print(\"Number of columns:\", columns_df_CM_mysterious)\n",
        "# Count non-zero values by row\n",
        "non_zero_counts = (df_CM_mysterious != 0).sum(axis=1)\n",
        "\n",
        "# Print the result\n",
        "print(non_zero_counts)\n",
        "#print (df)\n"
      ],
      "metadata": {
        "id": "9aMp6MpXddIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b36db2-16a4-4f1a-cd95-b5573b08741e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['sample', 'ARO:3000167', 'ARO:3002847', 'mrkb', 'enta', 'fepa',\n",
            "       'ARO:3004122', 'cyca', 'csge', 'iucc',\n",
            "       ...\n",
            "       'teml100', 'scintssj', 'wcst', 'sfax', 'kpsd', 'mdlb', 'ARO:3001084',\n",
            "       'tssj', 'icmftssm', 'acrr'],\n",
            "      dtype='object', length=506)\n",
            "   ID  ARO:3000167  ARO:3002847  mrkb  enta  fepa  ARO:3004122  cyca  csge  \\\n",
            "0  S1            0            0     0     0     0            0     1     0   \n",
            "1  S2            0            0     0     0     0            0     1     0   \n",
            "2  S3            0            0     0     0     0            0     1     0   \n",
            "3  S4            0            0     0     1     0            0     1     0   \n",
            "4  S5            0            0     0     0     0            0     1     0   \n",
            "\n",
            "   iucc  ...  teml100  scintssj  wcst  sfax  kpsd  mdlb  ARO:3001084  tssj  \\\n",
            "0     0  ...        0         0     0     0     0     0            0     0   \n",
            "1     0  ...        0         0     0     0     0     0            0     0   \n",
            "2     0  ...        0         0     0     0     0     0            0     0   \n",
            "3     0  ...        0         0     0     0     0     0            0     0   \n",
            "4     0  ...        0         0     0     0     0     0            0     0   \n",
            "\n",
            "   icmftssm  acrr  \n",
            "0         0     0  \n",
            "1         0     0  \n",
            "2         0     0  \n",
            "3         0     0  \n",
            "4         0     0  \n",
            "\n",
            "[5 rows x 506 columns]\n",
            "Number of rows: 146\n",
            "Number of columns: 506\n",
            "0       74\n",
            "1       79\n",
            "2       85\n",
            "3       85\n",
            "4       76\n",
            "      ... \n",
            "141    125\n",
            "142    126\n",
            "143    126\n",
            "144    118\n",
            "145    115\n",
            "Length: 146, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Adding metadata such as species to mysterious samples\n",
        "url = 'https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/01_preprocessing/amr_patterns.tsv'  # Replace with the actual GitHub URL of the CSV file\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_metadata_mysterious = pd.read_csv(url, delimiter='\\t')\n",
        "new_column = df_metadata_mysterious['ID']\n",
        "df_metadata_mysterious.insert(2, 'City', new_column)\n",
        "df_metadata_mysterious['City'] = 'mysterious'\n",
        "df_metadata_mysterious=df_metadata_mysterious.iloc[:, :4]\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df_metadata_mysterious.head())\n",
        "# Perform the join based on the 'Id' column\n",
        "mysterious_df = pd.merge( df_metadata_mysterious,df_CM_mysterious, on='ID')\n",
        "\n",
        "# Print the merged DataFrame\n",
        "print(mysterious_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q42vcqNBfO-F",
        "outputId": "cceb760f-6fec-49b9-9df6-200dbbbc9059"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                  Species        City AST-based group  ARO:3000167  \\\n",
            "0  S1  Enterobacter hormaechei  mysterious   3GC-resistant            0   \n",
            "1  S2  Enterobacter hormaechei  mysterious          CP CRE            0   \n",
            "2  S3  Enterobacter hormaechei  mysterious          CP CRE            0   \n",
            "3  S4  Enterobacter hormaechei  mysterious          CP CRE            0   \n",
            "4  S5  Enterobacter hormaechei  mysterious          CP CRE            0   \n",
            "\n",
            "   ARO:3002847  mrkb  enta  fepa  ARO:3004122  ...  teml100  scintssj  wcst  \\\n",
            "0            0     0     0     0            0  ...        0         0     0   \n",
            "1            0     0     0     0            0  ...        0         0     0   \n",
            "2            0     0     0     0            0  ...        0         0     0   \n",
            "3            0     0     1     0            0  ...        0         0     0   \n",
            "4            0     0     0     0            0  ...        0         0     0   \n",
            "\n",
            "   sfax  kpsd  mdlb  ARO:3001084  tssj  icmftssm  acrr  \n",
            "0     0     0     0            0     0         0     0  \n",
            "1     0     0     0            0     0         0     0  \n",
            "2     0     0     0            0     0         0     0  \n",
            "3     0     0     0            0     0         0     0  \n",
            "4     0     0     0            0     0         0     0  \n",
            "\n",
            "[5 rows x 509 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mysterious city has 146 sample 505 AMR markers\n"
      ],
      "metadata": {
        "id": "ZFijGzpMlbe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting consensus by city\n",
        "## Pending\n",
        "\n",
        "# Extract column 3\n",
        "\n",
        "#df=mysterious_df\n",
        "#df = df.drop(columns=[df.columns[0], df.columns[2], df.columns[3]])\n",
        "\n",
        "#grouped = df.groupby('Species').agg(lambda x: x.mode().iloc[0])\n",
        "\n",
        "# Print the result\n",
        "#print(grouped)\n",
        "# Count non-zero values by row\n",
        "#non_zero_counts = (df != 0).sum(axis=1)\n",
        "\n",
        "# Print the result\n",
        "#print(non_zero_counts)\n",
        "#print (df)"
      ],
      "metadata": {
        "id": "OFVc0YBklCSr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMR in Genomes  \n",
        "### Selected from NCBI  \n",
        "We found 3566 CARD Ids ( columns) not all of them are in the mysterious city samples.  \n",
        "The 106 rows are the genus _Escherichia_, _Enterobacter_ and _Klebsiella_ in the 6 US cities were AMR CARD models were found.\n"
      ],
      "metadata": {
        "id": "USj4OYdWhAdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## CARD table for Extracted by Taxonomy , binned by city\n",
        "url = 'https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/230623_genomes_card_presence.tsv'  # Replace with the actual GitHub URL of the CSV file\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_NCBI_genomes_AMR_CARD = pd.read_csv(url, delimiter='\\t').transpose()\n",
        "\n",
        "# Get the values from the third row\n",
        "third_row = df_NCBI_genomes_AMR_CARD.iloc[1]\n",
        "df_NCBI_genomes_AMR_CARD.columns=third_row\n",
        "\n",
        "# Add a prefix to column names\n",
        "prefix = 'ARO:'  # Replace with the desired prefix\n",
        "#df_NCBI_genomes_AMR_CARD = df_NCBI_genomes_AMR_CARD.iloc[1].astype(str) +\"_\"+ df_NCBI_genomes_AMR_CARD.add_prefix(prefix)\n",
        "df_NCBI_genomes_AMR_CARD = df_NCBI_genomes_AMR_CARD.add_prefix(prefix)\n",
        "\n",
        "# Remove a specific row by index\n",
        "index_to_remove = 'aro'  # Replace with the index of the row you want to remove\n",
        "df_NCBI_genomes_AMR_CARD = df_NCBI_genomes_AMR_CARD.drop(index_to_remove)\n",
        "\n",
        "#df_NCBI_genomes_AMR_CARD.columns=df_NCBI_genomes_AMR_CARD.iloc[0].astype(str)+\"_\"+df_NCBI_genomes_AMR_CARD.columns\n",
        "#print(names)\n",
        "print(df_NCBI_genomes_AMR_CARD)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b897022a-ea5f-4b95-b05b-43b39c9ad6c9",
        "id": "L7GauCTui59F"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aro             ARO:3000535 ARO:3003665 ARO:3000620 ARO:3005091 ARO:3007433  \\\n",
            "Unnamed: 0             macB        NmcR        adeL        RanA        almE   \n",
            "GCF_002214205.1           1           1           1           1           1   \n",
            "GCF_002833425.1           1           1           1           1           1   \n",
            "GCF_002833445.1           1           1           1           1           1   \n",
            "GCF_002833465.1           1           1           1           1           1   \n",
            "...                     ...         ...         ...         ...         ...   \n",
            "GCF_029069675.1           1           1           1           1           1   \n",
            "GCF_029069745.1           1           1           1           1           1   \n",
            "GCF_029069825.1           1           1           1           1           1   \n",
            "GCF_029070195.1           1           1           1           1           1   \n",
            "GCF_029075245.1           1           1           1           1           1   \n",
            "\n",
            "aro             ARO:3000833 ARO:3005008 ARO:3000813 ARO:3004047 ARO:3002985  \\\n",
            "Unnamed: 0             evgS         TxR        MexS        kdpD        arnA   \n",
            "GCF_002214205.1           1           1           1           1           1   \n",
            "GCF_002833425.1           1           1           1           1           1   \n",
            "GCF_002833445.1           1           1           1           1           1   \n",
            "GCF_002833465.1           1           1           1           1           1   \n",
            "...                     ...         ...         ...         ...         ...   \n",
            "GCF_029069675.1           1           1           1           1           1   \n",
            "GCF_029069745.1           1           1           1           1           1   \n",
            "GCF_029069825.1           1           1           1           1           1   \n",
            "GCF_029070195.1           1           1           1           1           1   \n",
            "GCF_029075245.1           1           1           1           1           1   \n",
            "\n",
            "aro              ... ARO:3006843 ARO:3001659 ARO:3000950 ARO:3003622  \\\n",
            "Unnamed: 0       ...      PDC-58     OXA-175      TEM-83     OXA-466   \n",
            "GCF_002214205.1  ...           0           0           0           0   \n",
            "GCF_002833425.1  ...           0           0           0           0   \n",
            "GCF_002833445.1  ...           0           0           0           0   \n",
            "GCF_002833465.1  ...           0           0           0           0   \n",
            "...              ...         ...         ...         ...         ...   \n",
            "GCF_029069675.1  ...           0           0           0           0   \n",
            "GCF_029069745.1  ...           0           0           0           0   \n",
            "GCF_029069825.1  ...           0           0           0           0   \n",
            "GCF_029070195.1  ...           0           0           0           0   \n",
            "GCF_029075245.1  ...           1           1           1           1   \n",
            "\n",
            "aro             ARO:3005371 ARO:3006685 ARO:3001838 ARO:3007239 ARO:3006522  \\\n",
            "Unnamed: 0           KPC-39     PDC-315      ACT-17    MCR-1.22     PDC-145   \n",
            "GCF_002214205.1           0           0           0           0           0   \n",
            "GCF_002833425.1           0           0           0           0           0   \n",
            "GCF_002833445.1           0           0           0           0           0   \n",
            "GCF_002833465.1           0           0           0           0           0   \n",
            "...                     ...         ...         ...         ...         ...   \n",
            "GCF_029069675.1           0           0           0           0           0   \n",
            "GCF_029069745.1           0           0           0           0           0   \n",
            "GCF_029069825.1           0           0           0           0           0   \n",
            "GCF_029070195.1           0           0           0           0           0   \n",
            "GCF_029075245.1           1           1           1           1           1   \n",
            "\n",
            "aro             ARO:3006415  \n",
            "Unnamed: 0          ADC-245  \n",
            "GCF_002214205.1           0  \n",
            "GCF_002833425.1           0  \n",
            "GCF_002833445.1           0  \n",
            "GCF_002833465.1           0  \n",
            "...                     ...  \n",
            "GCF_029069675.1           0  \n",
            "GCF_029069745.1           0  \n",
            "GCF_029069825.1           0  \n",
            "GCF_029070195.1           0  \n",
            "GCF_029075245.1           1  \n",
            "\n",
            "[107 rows x 3566 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will get the CARD Ids intersection with IDs in mysterious city samples, only 157 were found.  "
      ],
      "metadata": {
        "id": "4HL0uqI3IbyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create an empty column with the desired name\n",
        "new_column = df_NCBI_genomes_AMR_CARD.index\n",
        "\n",
        "# Get the intersection of column names\n",
        "common_columns = list(set(df_CM_mysterious.columns).intersection(df_NCBI_genomes_AMR_CARD.columns))\n",
        "\n",
        "# Keep only the common columns in both DataFrames\n",
        "#df1 = df_CM_mysterious[common_columns]\n",
        "df_NCBI_genomes_AMR_CARD = df_NCBI_genomes_AMR_CARD[common_columns]\n",
        "\n",
        "# Print the updated DataFrames with only the common columns\n",
        "# Assign the empty column as the first column in the DataFrame\n",
        "df_NCBI_genomes_AMR_CARD.insert(0, 'db', new_column)\n",
        "df_NCBI_genomes_AMR_CARD=df_NCBI_genomes_AMR_CARD.reset_index(drop=True)\n",
        "\n",
        "print(df_NCBI_genomes_AMR_CARD)\n",
        "\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df_ET_BC_AMR_CARD)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai4MmBeOHtME",
        "outputId": "5c96bf0f-1131-44f0-c6f9-7183d7ceb899"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aro               db  ARO:3002578 ARO:3000823 ARO:3000167 ARO:3003548  \\\n",
            "0         Unnamed: 0  AAC(6')-Ib7        ramA      tet(C)        mdtN   \n",
            "1    GCF_002214205.1            1           1           1           1   \n",
            "2    GCF_002833425.1            1           1           1           1   \n",
            "3    GCF_002833445.1            1           1           1           1   \n",
            "4    GCF_002833465.1            1           1           1           1   \n",
            "..               ...          ...         ...         ...         ...   \n",
            "102  GCF_029069675.1            0           1           1           1   \n",
            "103  GCF_029069745.1            0           1           1           1   \n",
            "104  GCF_029069825.1            0           1           1           1   \n",
            "105  GCF_029070195.1            0           1           1           1   \n",
            "106  GCF_029075245.1            1           1           1           1   \n",
            "\n",
            "aro ARO:3003059 ARO:3001130 ARO:3002705 ARO:3002735 ARO:3003578  ...  \\\n",
            "0          tmrB      SHV-76        floR      QnrB20        PmrF  ...   \n",
            "1             1           0           1           0           1  ...   \n",
            "2             1           0           1           0           1  ...   \n",
            "3             1           0           1           0           1  ...   \n",
            "4             1           0           1           0           1  ...   \n",
            "..          ...         ...         ...         ...         ...  ...   \n",
            "102           1           1           1           0           1  ...   \n",
            "103           1           1           0           0           1  ...   \n",
            "104           1           1           1           0           1  ...   \n",
            "105           1           1           1           0           1  ...   \n",
            "106           1           0           1           0           1  ...   \n",
            "\n",
            "aro ARO:3000263 ARO:3000508 ARO:3005098 ARO:3002132 ARO:3000792 ARO:3000873  \\\n",
            "0          marA        gadX        qacL       DHA-1        mdtA       TEM-1   \n",
            "1             1           1           1           0           1           1   \n",
            "2             1           1           1           0           1           1   \n",
            "3             1           1           1           0           1           1   \n",
            "4             1           1           1           0           1           1   \n",
            "..          ...         ...         ...         ...         ...         ...   \n",
            "102           1           1           1           0           1           1   \n",
            "103           1           1           1           0           1           1   \n",
            "104           1           1           1           0           1           1   \n",
            "105           1           1           1           0           1           1   \n",
            "106           1           1           1           0           1           1   \n",
            "\n",
            "aro ARO:3001216 ARO:3001214 ARO:3000676 ARO:3003838  \n",
            "0          mdtH        mdtM        H-NS        gadW  \n",
            "1             1           1           1           1  \n",
            "2             1           1           1           1  \n",
            "3             1           1           1           1  \n",
            "4             1           1           1           1  \n",
            "..          ...         ...         ...         ...  \n",
            "102           1           1           1           0  \n",
            "103           1           1           1           0  \n",
            "104           1           1           1           0  \n",
            "105           1           1           1           0  \n",
            "106           1           1           1           1  \n",
            "\n",
            "[107 rows x 157 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets find all hits of the manually curated database 325 Ids were blastn against metagenomic samples"
      ],
      "metadata": {
        "id": "GHKODGp6J__h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url2='https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/230624_genomes_blast_counts.tsv'\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_NCBI_genomes_AMR_BLASTn = pd.read_csv(url2, delimiter='\\t', dtype={'002214205': str})\n",
        "df_NCBI_genomes_AMR_BLASTn['db'] = \"GCF_\" + df_NCBI_genomes_AMR_BLASTn['002214205'].astype(str) + \".1\"\n",
        "\n",
        "# Create an empty column with the desired name\n",
        "new_column = df_NCBI_genomes_AMR_BLASTn['db']\n",
        "\n",
        "# Get the intersection of column names\n",
        "common_columns = list(set(df_CM_mysterious.columns).intersection(df_NCBI_genomes_AMR_BLASTn))\n",
        "\n",
        "# Keep only the common columns in both DataFrames\n",
        "df1 = df_CM_mysterious[common_columns]\n",
        "df_NCBI_genomes_AMR_BLASTn= df_NCBI_genomes_AMR_BLASTn[common_columns]\n",
        "# Transform DataFrame to boolean\n",
        "df_boolean = df_NCBI_genomes_AMR_BLASTn.astype(bool)\n",
        "# Convert boolean values back to numeric\n",
        "df_NCBI_genomes_AMR_BLASTn = df_boolean.astype(int)\n",
        "\n",
        "\n",
        "# Assign the empty column as the first column in the DataFrame\n",
        "df_NCBI_genomes_AMR_BLASTn.insert(0, 'db', new_column)\n",
        "df_NCBI_genomes_AMR_BLASTn=df_NCBI_genomes_AMR_BLASTn.reset_index(drop=True)\n",
        "\n",
        "# Print the updated DataFrames with only the common columns\n",
        "#print(df1)\n",
        "print(df_NCBI_genomes_AMR_BLASTn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5eXdZ5umQE_",
        "outputId": "2c5d19b4-d8af-4706-b149-5dde300734fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  db  porin  kfoc  iucc  flha  fepd  clbo  ec148  tli1  kpsf  \\\n",
            "0    GCF_002214205.1      0     0     1     0     0     0      0     0     1   \n",
            "1    GCF_002833425.1      0     0     0     0     0     0      0     0     0   \n",
            "2    GCF_002833445.1      0     0     0     0     0     0      0     0     0   \n",
            "3    GCF_002833465.1      0     0     0     0     0     0      0     0     0   \n",
            "4    GCF_002855915.1      0     0     0     0     0     0      0     0     0   \n",
            "..               ...    ...   ...   ...   ...   ...   ...    ...   ...   ...   \n",
            "293  GCF_029069675.1      0     0     0     0     1     0      0     0     0   \n",
            "294  GCF_029069745.1      0     0     0     0     1     0      0     0     0   \n",
            "295  GCF_029069825.1      0     0     0     0     1     0      0     0     0   \n",
            "296  GCF_029070195.1      0     0     0     0     1     0      0     0     0   \n",
            "297  GCF_029075245.1      0     0     0     0     1     0      0     0     0   \n",
            "\n",
            "     ...  kpsc  acra  ramr  uhpt  cyca  clpvtssh  wcai  estxsat1  mrkh  wcly  \n",
            "0    ...     0     1     0     0     0         0     0         0     0     0  \n",
            "1    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "2    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "3    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "4    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "..   ...   ...   ...   ...   ...   ...       ...   ...       ...   ...   ...  \n",
            "293  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "294  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "295  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "296  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "297  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "\n",
            "[298 rows x 326 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this data set rows with same ID may came from different pangenome Set (clous, shell, persistance) for this analysis we will combine rows by OR operator ignoring its pangenome origin\n"
      ],
      "metadata": {
        "id": "yn-wlJTdllDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_NCBI_genomes_AMR_BLASTn)\n",
        "# Group the DataFrame by 'ID' and apply the OR operator to each column\n",
        "df_NCBI_genomes_blast_combined = df_NCBI_genomes_AMR_BLASTn.groupby('db').agg(lambda x: 1 if any(x.astype(bool)) else 0)\n",
        "\n",
        "# Reset the index to convert the 'ID' column back to a regular column\n",
        "df_NCBI_genomes_blast_combined.reset_index(inplace=True)\n",
        "#print(df_NCBI_genomes_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGHTXfwoljdS",
        "outputId": "f53809b4-adf7-41bd-a4eb-a749cd1419e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  db  porin  kfoc  iucc  flha  fepd  clbo  ec148  tli1  kpsf  \\\n",
            "0    GCF_002214205.1      0     0     1     0     0     0      0     0     1   \n",
            "1    GCF_002833425.1      0     0     0     0     0     0      0     0     0   \n",
            "2    GCF_002833445.1      0     0     0     0     0     0      0     0     0   \n",
            "3    GCF_002833465.1      0     0     0     0     0     0      0     0     0   \n",
            "4    GCF_002855915.1      0     0     0     0     0     0      0     0     0   \n",
            "..               ...    ...   ...   ...   ...   ...   ...    ...   ...   ...   \n",
            "293  GCF_029069675.1      0     0     0     0     1     0      0     0     0   \n",
            "294  GCF_029069745.1      0     0     0     0     1     0      0     0     0   \n",
            "295  GCF_029069825.1      0     0     0     0     1     0      0     0     0   \n",
            "296  GCF_029070195.1      0     0     0     0     1     0      0     0     0   \n",
            "297  GCF_029075245.1      0     0     0     0     1     0      0     0     0   \n",
            "\n",
            "     ...  kpsc  acra  ramr  uhpt  cyca  clpvtssh  wcai  estxsat1  mrkh  wcly  \n",
            "0    ...     0     1     0     0     0         0     0         0     0     0  \n",
            "1    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "2    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "3    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "4    ...     0     0     0     0     0         0     0         0     0     0  \n",
            "..   ...   ...   ...   ...   ...   ...       ...   ...       ...   ...   ...  \n",
            "293  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "294  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "295  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "296  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "297  ...     0     1     0     1     1         1     0         0     0     0  \n",
            "\n",
            "[298 rows x 326 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets horizontally combined the two datasets, so that for each city we will have 157+325 =482 AMR IDS"
      ],
      "metadata": {
        "id": "x8uTrSe_K1fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_NCBIGenomes_df = pd.merge(df_NCBI_genomes_blast_combined, df_NCBI_genomes_AMR_CARD, on='db')\n",
        "merged_NCBIGenomes_df.rename(columns={'db': 'ID'}, inplace=True)\n",
        "\n",
        "url='https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/genome-metadata.csv'\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_NCBI_genomes_metadata = pd.read_csv(url)\n",
        "df_NCBI_genomes_metadata.rename(columns={'accession': 'ID'}, inplace=True)\n",
        "\n",
        "merged_df = pd.merge(df_NCBI_genomes_metadata, merged_NCBIGenomes_df, on=\"ID\")\n",
        "merged_df.rename(columns={'city': 'City'}, inplace=True)\n",
        "merged_df.rename(columns={'species': 'Species'}, inplace=True)\n",
        "merged_df['City']=merged_df['City'].replace(\"New York\", \"NYC\").replace(\"Minneapolis\", \"MIN\").replace(\"Baltimore\", \"BAL\").replace(\"San Antonio\", \"SAN\")\n",
        "merged_df['ID']=merged_df['City']+\"_\"+merged_df['Collection_date'].astype(str)+\"_\"+merged_df['ID']\n",
        "\n",
        "\n",
        "\n",
        "print(merged_df)\n",
        " #ID                  Species        City\n",
        " #ID ="
      ],
      "metadata": {
        "id": "D75UJhX8K6bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NCBI Genomes has 105 samples with 486 AMR markers"
      ],
      "metadata": {
        "id": "igq6TA95lybM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets combine the 107 rows from genomes and ~480 AMR Ids with\n",
        "~146 rows with ~505 AMR markers from mysterious city"
      ],
      "metadata": {
        "id": "C53bztYtMguK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata from collected genomes"
      ],
      "metadata": {
        "id": "zhNm2qRHEiO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_df NCBI samples with metadata\n",
        "metadata_df = pd.concat([mysterious_df, merged_df], axis=0, ignore_index=True).fillna(0)\n",
        "print(metadata_df)\n"
      ],
      "metadata": {
        "id": "RlELQrO8TN-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mysterious city and NCBI genomes combined has 251 samples with 511 columns"
      ],
      "metadata": {
        "id": "rhdj98vHmDRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMR in metagenomes\n",
        "### Extracted by taxonomy - Binned by city - Assembled - AMR profiled  \n",
        "We found 492 CARD Ids ( columns) not all of them are in the mysterious city samples.\n",
        "The 12 rows are the genus Escherichia, Enterobacter and Klebsiella in the 6 US cities were AMR CARD models were found.\n"
      ],
      "metadata": {
        "id": "sKa59kd-Zzoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## CARD table for Extracted by Taxonomy , binned by city\n",
        "url = 'https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/230628_us_reads_card_counts.tsv'  # Replace with the actual GitHub URL of the CSV file\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_ET_BC_AMR_CARD = pd.read_csv(url, delimiter='\\t').transpose()\n",
        "\n",
        "# Get the values from the third row\n",
        "third_row = df_ET_BC_AMR_CARD.iloc[1]\n",
        "df_ET_BC_AMR_CARD.columns=third_row\n",
        "# Add a prefix to column names\n",
        "prefix = 'ARO:'  # Replace with the desired prefix\n",
        "df_ET_BC_AMR_CARD = df_ET_BC_AMR_CARD.add_prefix(prefix)\n",
        "\n",
        "# Remove a specific row by index\n",
        "index_to_remove = 'aro'  # Replace with the index of the row you want to remove\n",
        "df_ET_BC_AMR_CARD = df_ET_BC_AMR_CARD.drop(index_to_remove)\n",
        "df_ET_BC_AMR_CARD.columns=df_ET_BC_AMR_CARD.iloc[0].astype(str)+\"_\"+df_ET_BC_AMR_CARD.columns\n",
        "\n",
        "print(df_ET_BC_AMR_CARD)\n"
      ],
      "metadata": {
        "id": "H672VP5rZ30j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will get the CARD Ids intersection with IDs in mysterious city samples, only 78 were found.\n",
        "\n"
      ],
      "metadata": {
        "id": "nZ6CULUBa8En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty column with the desired name\n",
        "new_column = df_ET_BC_AMR_CARD.index\n",
        "\n",
        "# Get the intersection of column names\n",
        "common_columns = list(set(df_CM_mysterious.columns).intersection(df_ET_BC_AMR_CARD.columns))\n",
        "\n",
        "# Keep only the common columns in both DataFrames\n",
        "#df1 = df_CM_mysterious[common_columns]\n",
        "df_ET_BC_AMR_CARD = df_ET_BC_AMR_CARD[common_columns]\n",
        "\n",
        "# Print the updated DataFrames with only the common columns\n",
        "# Assign the empty column as the first column in the DataFrame\n",
        "df_ET_BC_AMR_CARD.insert(0, 'db', new_column)\n",
        "df_ET_BC_AMR_CARD=df_ET_BC_AMR_CARD.reset_index(drop=True)\n",
        "\n",
        "print(df_ET_BC_AMR_CARD)\n",
        "\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df_ET_BC_AMR_CARD)\n"
      ],
      "metadata": {
        "id": "noTg6X1Na9JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets find all hits of the manually curated database 325 Ids were blastn against metagenomic samples\n",
        "\n"
      ],
      "metadata": {
        "id": "-86fiQkubTwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url2='https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/amr_counts_complement_a3_20230629.tsv'\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_ET_BC_AMR_BLASTn = pd.read_csv(url2, delimiter='\\t')\n",
        "df_ET_BC_AMR_BLASTn['db'] = df_ET_BC_AMR_BLASTn['db'].str.split('.').str[0]\n",
        "\n",
        "# Create an empty column with the desired name\n",
        "new_column = df_ET_BC_AMR_BLASTn['db']\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df_ET_BC_AMR_BLASTn)\n",
        "\n",
        "# Get the intersection of column names\n",
        "common_columns = list(set(df_CM_mysterious.columns).intersection(df_ET_BC_AMR_BLASTn))\n",
        "\n",
        "# Keep only the common columns in both DataFrames\n",
        "#df1 = df_CM_mysterious[common_columns]\n",
        "df_ET_BC_AMR_BLASTn= df_ET_BC_AMR_BLASTn[common_columns]\n",
        "# Transform DataFrame to boolean\n",
        "df_boolean = df_ET_BC_AMR_BLASTn.astype(bool)\n",
        "# Convert boolean values back to numeric\n",
        "df_ET_BC_AMR_BLASTn = df_boolean.astype(int)\n",
        "\n",
        "\n",
        "# Assign the empty column as the first column in the DataFrame\n",
        "df_ET_BC_AMR_BLASTn.insert(0, 'db', new_column)\n",
        "df_ET_BC_AMR_BLASTn=df_ET_BC_AMR_BLASTn.reset_index(drop=True)\n",
        "\n",
        "# Print the updated DataFrames with only the common columns\n",
        "#print(df1)\n",
        "print(df_ET_BC_AMR_BLASTn)"
      ],
      "metadata": {
        "id": "XEPqV9VTbMFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets horizontally combined the two datasets, so that for each city we will have 78+325 =403 AMR IDS\n",
        "\n"
      ],
      "metadata": {
        "id": "EWc3p_n-boQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOfbicKbcbTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df_ET_BC_AMR_BLASTn['db'])\n",
        "#print(df_ET_BC_AMR_CARD['db'])\n",
        "merged_ETBCMet_df = pd.merge(df_ET_BC_AMR_BLASTn, df_ET_BC_AMR_CARD, on='db')\n",
        "merged_ETBCMet_df.rename(columns={'db': 'ID'}, inplace=True)\n",
        "print(merged_ETBCMet_df)"
      ],
      "metadata": {
        "id": "6k99W9EHbzV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_column1 =merged_ETBCMet_df['ID'].str.split('_').str[0]\n",
        "new_column2 =merged_ETBCMet_df['ID'].str.split('_').str[1].replace(\"En\", \"Enterobacter hormaechei\").replace(\"Es\", \"Escherichia coli\").replace(\"Kl\", \"Klebsiella pneumoniae\")\n",
        "\n",
        "merged_ETBCMet_df.insert(1, 'Species', new_column2)\n",
        "merged_ETBCMet_df.insert(2, 'City', new_column1)\n",
        "\n",
        "merged_ETBCMet_df=merged_ETBCMet_df.reset_index(drop=True)\n",
        "#merged_COA_df=merged_COA_df.iloc[:, :3]\n",
        "print(merged_ETBCMet_df)"
      ],
      "metadata": {
        "id": "TmshXgEljrmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coassembled by city - Extracted by taxonomy - AMR profiled\n",
        "We found 549 CARD Ids ( columns) not all of them are in the mysterious city samples.\n",
        "The 19 rows are the genus Escherichia, Enterobacter and Klebsiella in the 6 US cities were AMR CARD models were found."
      ],
      "metadata": {
        "id": "9zPOu0NxchU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## CARD table for Extracted by Taxonomy , binned by city\n",
        "url = 'https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/230628_us_coassemblies_card_presence.tsv'  # Replace with the actual GitHub URL of the CSV file\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_COA_CARD = pd.read_csv(url, delimiter='\\t').transpose()\n",
        "\n",
        "# Get the values from the third row\n",
        "third_row = df_COA_CARD.iloc[1]\n",
        "df_COA_CARD.columns=third_row\n",
        "# Add a prefix to column names\n",
        "prefix = 'ARO:'  # Replace with the desired prefix\n",
        "df_COA_CARD = df_COA_CARD.add_prefix(prefix)\n",
        "\n",
        "#df_COA_CARD.iloc[:, 0] = df_COA_CARD.iloc[:, 0].add_suffix('_COA')\n",
        "df_COA_CARD = df_COA_CARD.rename(lambda x: str(x) + '_COA', axis='index')\n",
        "\n",
        "\n",
        "# Remove a specific row by index\n",
        "index_to_remove = 'aro_COA'  # Replace with the index of the row you want to remove\n",
        "df_COA_CARD = df_COA_CARD.drop(index_to_remove)\n",
        "\n",
        "\n",
        "print(df_COA_CARD)\n",
        "#print( df_COA_CARD.index.tolist())\n"
      ],
      "metadata": {
        "id": "IorIgoRZccSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARD **intersection** gives 80 common columns (CARD IDs) with mysterious sample"
      ],
      "metadata": {
        "id": "UcbByaYHdSkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an empty column with the desired name\n",
        "new_column = df_COA_CARD.index\n",
        "\n",
        "# Get the intersection of column names\n",
        "common_columns = list(set(df_CM_mysterious.columns).intersection(df_COA_CARD.columns))\n",
        "\n",
        "# Keep only the common columns in both DataFrames\n",
        "#df1 = df_CM_mysterious[common_columns]\n",
        "df_COA_CARD = df_COA_CARD[common_columns]\n",
        "\n",
        "# Print the updated DataFrames with only the common columns\n",
        "# Assign the empty column as the first column in the DataFrame\n",
        "df_COA_CARD.insert(0, 'db', new_column)\n",
        "df_COA_CARD=df_COA_CARD.reset_index(drop=True)\n",
        "\n",
        "print(df_COA_CARD)\n",
        "\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df_COA_CARD)\n"
      ],
      "metadata": {
        "id": "dE8vRby6dUps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets find all hits of the manually curated database 325 Ids were blastn against metagenomic samples\n",
        "\n"
      ],
      "metadata": {
        "id": "pZuSUzcIdynA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "url2='https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/data/amr_counts_complement_b3_20230629.tsv'\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df_COA_BLASTn = pd.read_csv(url2, delimiter='\\t')\n",
        "df_COA_BLASTn['db'] = df_COA_BLASTn['db'].str.split('.').str[0]\n",
        "\n",
        "# Create an empty column with the desired name\n",
        "new_column = df_COA_BLASTn['db']+ '_COA'\n",
        "\n",
        "#df_COA_BLASTn = df_COA_BLASTn.rename(lambda x: str(x) + '_COA', axis='index')\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df_COA_BLASTn)\n",
        "\n",
        "# Get the intersection of column names\n",
        "common_columns = list(set(df_CM_mysterious.columns).intersection(df_COA_BLASTn))\n",
        "\n",
        "# Keep only the common columns in both DataFrames\n",
        "#df1 = df_CM_mysterious[common_columns]\n",
        "df_COA_BLASTn= df_COA_BLASTn[common_columns]\n",
        "# Transform DataFrame to boolean\n",
        "df_boolean = df_COA_BLASTn.astype(bool)\n",
        "# Convert boolean values back to numeric\n",
        "df_COA_BLASTn = df_boolean.astype(int)\n",
        "\n",
        "\n",
        "# Assign the empty column as the first column in the DataFrame\n",
        "df_COA_BLASTn.insert(0, 'db', new_column)\n",
        "df_COA_BLASTn=df_COA_BLASTn.reset_index(drop=True)\n",
        "\n",
        "# Print the updated DataFrames with only the common columns\n",
        "#print(df1)\n",
        "print(df_COA_BLASTn)\n"
      ],
      "metadata": {
        "id": "Kez9TkGneATe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "horizontal"
      ],
      "metadata": {
        "id": "u2iA1meaept4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print(df_ET_BC_AMR_BLASTn['db'])\n",
        "#print(df_ET_BC_AMR_CARD['db'])\n",
        "merged_COA_df = pd.merge(df_COA_BLASTn, df_COA_CARD, on='db')\n",
        "merged_COA_df.rename(columns={'db': 'ID'}, inplace=True)\n",
        "print(merged_COA_df)"
      ],
      "metadata": {
        "id": "0gH58J37erFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_column1 =merged_COA_df['ID'].str.split('_').str[0]\n",
        "new_column2 =merged_COA_df['ID'].str.split('_').str[1].replace(\"En\", \"Enterobacter hormaechei\").replace(\"Es\", \"Escherichia coli\").replace(\"Kl\", \"Klebsiella pneumoniae\")\n",
        "\n",
        "merged_COA_df.insert(1, 'Species', new_column2)\n",
        "merged_COA_df.insert(2, 'City', new_column1)\n",
        "\n",
        "merged_COA_df=merged_COA_df.reset_index(drop=True)\n",
        "#merged_COA_df=merged_COA_df.iloc[:, :3]\n",
        "print(merged_COA_df)"
      ],
      "metadata": {
        "id": "xizsJFYKi-OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Vertically join the DataFrames keeping all columns from df1\n",
        "concatenated_df = pd.concat([metadata_df, merged_ETBCMet_df,merged_COA_df], axis=0, ignore_index=True).fillna(0)\n",
        "print(concatenated_df)"
      ],
      "metadata": {
        "id": "hXgMipvHiIbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_last_column(dataframe):\n",
        "    last_column = dataframe.columns[-1]  # Get the name of the last column\n",
        "    num_columns = len(dataframe.columns)  # Get the total number of columns\n",
        "    # Reorder the columns by moving the last column to position 6\n",
        "    dataframe2 = dataframe[[col for col in dataframe.columns if col != last_column]]\n",
        "    dataframe2.insert(4, last_column, dataframe.iloc[:, -1].astype(str) )\n",
        "    #print(\"last column\",last_column,dataframe2.columns[4])\n",
        "    #print(dataframe2.iloc[:,4])\n",
        "    #print(dataframe2)\n",
        "    return dataframe2\n",
        "\n",
        "# Assuming you have a dataframe named \"df\"\n",
        "updated_df = move_last_column(concatenated_df)\n",
        "updated_df2 = move_last_column(updated_df)\n",
        "\n",
        "print(updated_df2)"
      ],
      "metadata": {
        "id": "uGhM77G9TKq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dictionary\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/ccm-bioinfo/cambda2023/main/06_amr_resistance/codigos/data_preparation/data/aro_index.tsv'\n",
        "\n",
        "# Read the data from the URL into a DataFrame\n",
        "df = pd.read_csv(url, delimiter='\\t')\n",
        "\n",
        "# Assuming you have a DataFrame named df\n",
        "# Create an empty dictionary\n",
        "my_dict = {}\n",
        "\n",
        "# Iterate over the rows of the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Use the first column as the key and the fourth column as the value\n",
        "    key = row.iloc[0]\n",
        "    value = row.iloc[4]+\"_\"+row.iloc[0]\n",
        "    my_dict[key] = value\n",
        "\n",
        "# Now you have a dictionary where the first column serves as keys and the fourth column serves as values\n",
        "#print(my_dict)\n",
        "\n",
        "\n",
        "#concatenated_df.columns=concatenated_df.iloc[0].astype(str)+\"_\"+concatenated_df.columns\n",
        "def replace_columns_with_values(dataframe, replacements_dict):\n",
        "    renamed_dataframe = dataframe.rename(columns=replacements_dict)\n",
        "    return renamed_dataframe\n",
        "\n",
        "# Assuming you have a dataframe named \"other_df\"\n",
        "# and a dictionary named \"aro_dict\" with column replacements\n",
        "\n",
        "updated_df  = replace_columns_with_values(updated_df2 , my_dict)\n",
        "\n",
        "# Sort alfabetically\n",
        "# Get the first four columns and store them in a separate DataFrame\n",
        "first_four_columns = updated_df .iloc[:, :5]\n",
        "\n",
        "# Sort the remaining columns alphabetically\n",
        "sorted_remaining_columns = updated_df .iloc[:, 5:].sort_index(axis=1, key=lambda x: x.str.lower())\n",
        "\n",
        "# Concatenate the first four columns and the sorted remaining columns\n",
        "sorted_df = pd.concat([first_four_columns, sorted_remaining_columns], axis=1)\n",
        "\n",
        "# Display the sorted DataFrame\n",
        "print(sorted_df)\n",
        "\n",
        "# Display the sorted DataFrame\n",
        "print(sorted_df)\n"
      ],
      "metadata": {
        "id": "l7ydotFlXtNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print table\n"
      ],
      "metadata": {
        "id": "gb16d1hPk1YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have a DataFrame named concatenated_df\n",
        "\n",
        "# Export the DataFrame as a CSV file\n",
        "csv_file_path = '230705_AMR_mysterious_NCBI_all_nelly.csv'\n",
        "sorted_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Print the file paths\n",
        "print(\"CSV file saved:\", csv_file_path)"
      ],
      "metadata": {
        "id": "9SR9Qw-6k3JI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}